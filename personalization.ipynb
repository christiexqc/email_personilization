{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import statsmodels.formula.api as sm\n",
    "import seaborn as sns\n",
    "import sklearn as sl\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.width', 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./dataset/emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>email_text</th>\n",
       "      <th>email_version</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>user_country</th>\n",
       "      <th>user_past_purchases</th>\n",
       "      <th>clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>short_email</td>\n",
       "      <td>generic</td>\n",
       "      <td>9</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>US</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>long_email</td>\n",
       "      <td>personalized</td>\n",
       "      <td>6</td>\n",
       "      <td>Monday</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>short_email</td>\n",
       "      <td>generic</td>\n",
       "      <td>14</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>US</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>long_email</td>\n",
       "      <td>personalized</td>\n",
       "      <td>11</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>short_email</td>\n",
       "      <td>generic</td>\n",
       "      <td>8</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>UK</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   email_id   email_text email_version  hour    weekday user_country  user_past_purchases  clicked\n",
       "0         8  short_email       generic     9   Thursday           US                    3        0\n",
       "1        33   long_email  personalized     6     Monday           US                    0        0\n",
       "2        46  short_email       generic    14    Tuesday           US                    3        0\n",
       "3        49   long_email  personalized    11   Thursday           US                   10        0\n",
       "4        65  short_email       generic     8  Wednesday           UK                    3        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we talk about personalization and data science, the first thing that comes to the mind is Netflix-like personalization. I.e. given that you enjoyed these movies, we think you might like these other movies. Despite the fact that that’s the kind of personalization people tend to talk about the most, in the reality it is just a small subset of the types of personalization data scientists work on, and for sure not the most common.\n",
    "\n",
    "The most common application of personalization is something that can be well exemplified by the email dataset we worked on in the insight section.\n",
    "Extracting insights has helped us understand how each variable impacts the output. So, for instance, we found out that personalized as well as short emails are better, we should send emails on weekdays, etc. However, the fact that on an average short emails are better, doesn’t imply that short emails are better for every user we have. The goal of personalization is to take insights one step further and find the best email characteristics for each user. So a given user will receive a long email, another one a short one, one will receive it in the night, and one in the morning, etc.\n",
    "\n",
    "The sections below will describe how we can use the email dataset to come up with a personalized email strategy. This is how 90% of personalization is implemented on-line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the model, we choose to bin the continuous variables. I.e. hour will be binned into 3 groups (morning, afternoon, night) and purchase into the following 4 groups: [=0, between 1 and 3, 4-7, and >7]. We bin mainly to speed up the code, to make the output simpler, and also to remove a bit of noise. However, binning is not strictly required, and if you choose to not bin, the approach is exactly the same. It will just take a bit longer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>hour</th>\n",
       "      <th>user_past_purchases</th>\n",
       "      <th>clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99950.000000</td>\n",
       "      <td>99950.000000</td>\n",
       "      <td>99950.000000</td>\n",
       "      <td>99950.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>498695.729065</td>\n",
       "      <td>9.059100</td>\n",
       "      <td>3.878559</td>\n",
       "      <td>0.02070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>289226.115244</td>\n",
       "      <td>4.439618</td>\n",
       "      <td>3.196324</td>\n",
       "      <td>0.14238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>246721.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>498441.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>749936.750000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999998.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            email_id          hour  user_past_purchases      clicked\n",
       "count   99950.000000  99950.000000         99950.000000  99950.00000\n",
       "mean   498695.729065      9.059100             3.878559      0.02070\n",
       "std    289226.115244      4.439618             3.196324      0.14238\n",
       "min         8.000000      1.000000             0.000000      0.00000\n",
       "25%    246721.500000      6.000000             1.000000      0.00000\n",
       "50%    498441.500000      9.000000             3.000000      0.00000\n",
       "75%    749936.750000     12.000000             6.000000      0.00000\n",
       "max    999998.000000     24.000000            22.000000      1.00000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99950, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bin the variables accoding to the rules described above\n",
    "#Hour\n",
    "data['hour_binned']=pd.cut(data['hour'], bins=[1,5, 13, 21, 24], include_lowest=True, labels=['night', 'morning', 'afternoon', 'night2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "morning      60319\n",
       "night        23152\n",
       "afternoon    16062\n",
       "night2         417\n",
       "Name: hour_binned, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['hour_binned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace night2 with night\n",
    "data['hour_binned']=data['hour_binned'].replace('night2', 'night').cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bin purchases\n",
    "data['purchase_binned']=pd.cut(data['user_past_purchases'], bins=[0,1, 4, 8, 23], include_lowest=True, right=False, labels=['None', 'Low', 'Medium', 'High'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a20a4c588>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='clicked',data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the data for the model\n",
    "data_dummy = pd.get_dummies(data, drop_first=True).drop(['email_id', 'hour', 'user_past_purchases'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test to avoid overfitting\n",
    "train, test = train_test_split(data_dummy, test_size = 0.34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 0.05, 1: 0.95}, n_estimators=50,\n",
       "                       oob_score=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build the model. We choose a RF, but this personalization approach works with any kinds of models\n",
    "rf = RandomForestClassifier(class_weight={0:0.05,1:0.95}, n_estimators=50, oob_score=True)\n",
    "rf.fit(train.drop('clicked', axis=1), train['clicked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0     1\n",
      "0  59235  5366\n",
      "1   1041   325\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(confusion_matrix(train['clicked'], rf.oob_decision_function_[:,1].round(), labels=[0, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0     1\n",
      "0  30751  2529\n",
      "1    557   146\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(confusion_matrix(test['clicked'], rf.predict(test.drop('clicked', axis=1)), labels=[0, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOB and test error are very similar, so we are confident we are not overfitting. And overall the model is working pretty well. We only had 2% of clicks, but despite that the model is not predicting all events as class 0, we actually manage to predict ~23% of clicks (changing weights helped). And class 0 error didn’t go up that much either, being below 9%.\n",
    "\n",
    "Predict click-through-rate for each segment\n",
    "\n",
    "The second step is to create a new dataset with all unique combinations of our variables. We will then feed this dataset into the model and, for each unique combination, we will get a prediction. The model prediction represents click-rate and, therefore, this step is meant to estimate probability of clicking for each unique combination of country, # of purchases, email text, weekday, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We remove the label, we don't need it here\n",
    "data_unique = data_dummy.drop(['clicked'], axis=1)\n",
    "  \n",
    "#We create all unique combinations of our features\n",
    "data_unique = data_unique.drop_duplicates()\n",
    "  \n",
    "#Now we feed this into our model and get a pre\n",
    "predictions = rf.predict_proba(data_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73558808, 0.26441192],\n",
       "       [1.        , 0.        ],\n",
       "       [0.83832145, 0.16167855],\n",
       "       ...,\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, we add these predictions to the dataset\n",
    "data_unique['prediction'] = [x[1] for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_text_short_email</th>\n",
       "      <th>email_version_personalized</th>\n",
       "      <th>weekday_Monday</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "      <th>user_country_FR</th>\n",
       "      <th>user_country_UK</th>\n",
       "      <th>user_country_US</th>\n",
       "      <th>hour_binned_morning</th>\n",
       "      <th>hour_binned_afternoon</th>\n",
       "      <th>purchase_binned_Low</th>\n",
       "      <th>purchase_binned_Medium</th>\n",
       "      <th>purchase_binned_High</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.264412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.161679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.725791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   email_text_short_email  email_version_personalized  weekday_Monday  weekday_Saturday  weekday_Sunday  weekday_Thursday  weekday_Tuesday  weekday_Wednesday  user_country_FR  user_country_UK  user_country_US  hour_binned_morning  hour_binned_afternoon  purchase_binned_Low  purchase_binned_Medium  purchase_binned_High  prediction\n",
       "0                       1                           0               0                 0               0                 1                0                  0                0                0                1                    1                      0                    1                       0                     0    0.264412\n",
       "1                       0                           1               1                 0               0                 0                0                  0                0                0                1                    1                      0                    0                       0                     0    0.000000\n",
       "2                       1                           0               0                 0               0                 0                1                  0                0                0                1                    0                      1                    1                       0                     0    0.161679\n",
       "3                       0                           1               0                 0               0                 1                0                  0                0                0                1                    1                      0                    0                       0                     1    0.725791\n",
       "4                       1                           0               0                 0               0                 0                0                  1                0                1                0                    1                      0                    1                       0                     0    0.478043"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third step is to identify the variables that can be personalized. This typically means separating user characteristics from product characteristics, and focus on the second ones. After all, you can choose when to send the email or its message, but you can’t realistically move a customer from Spain to UK.\n",
    "\n",
    "Then, you group by unique combinations of user characteristics and find the product characteristics with the highest probability of clicking. So, for instance, one group will be US customers with 0 purchases (these are user characteristics). And then we will look for the combination of all the other variables that maximize probability of clicking. And that’s it. That combination will tell us how our product should be for those users and we will send emails accordingly. The more variables you have about your users, the more granular will be the groups and, therefore, the more specific will be the personalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by prediction. This way highest predictions will be at the top of the dataset \n",
    "data_unique = data_unique.sort_values('prediction', ascending=False)\n",
    "  \n",
    "#Remove duplicates for country and purchase binned. This way, for each unique combination of country and purchase,\n",
    "#we will only have the top 1 value, which means the highest prediction\n",
    "best_segment = data_unique.drop_duplicates(subset=['user_country_FR', 'user_country_UK', 'user_country_US', \n",
    "                                         'purchase_binned_Low', 'purchase_binned_Medium', 'purchase_binned_High'\n",
    "                                         ]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is not strictly needed. However, it is pretty hard to read that dataset cause we have all the dummy variables\n",
    "#So let's reconstruct manually the original categorical varibles. It will be so much clearer that way\n",
    "#Country\n",
    "best_segment['user_country'] = np.where(best_segment['user_country_UK'] == 1, \"UK\", \n",
    "                                   np.where(best_segment['user_country_US'] == 1, \"US\", \n",
    "                                      np.where(best_segment['user_country_FR'] == 1, \"FR\",\n",
    "                                     \"ES\"\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_segment = best_segment.drop([e for e in list(data_unique) if e.startswith('user_country_')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number_purchases\n",
    "best_segment['purchase_binned'] = np.where(best_segment['purchase_binned_High'] == 1, \"High\", \n",
    "                                   np.where(best_segment['purchase_binned_Medium'] == 1, \"Medium\", \n",
    "                                    np.where(best_segment['purchase_binned_Low'] == 1, \"Low\",\n",
    "                                     \"None\"\n",
    ")))\n",
    "best_segment = best_segment.drop([e for e in list(data_unique) if e.startswith('purchase_binned_')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Email Text\n",
    "best_segment['email_text'] = np.where(best_segment['email_text_short_email'] == 1, \"short_email\", \"long_email\")\n",
    "best_segment = best_segment.drop('email_text_short_email', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Email version\n",
    "best_segment['email_version'] = np.where(best_segment['email_version_personalized'] == 1, \"personalized\", \"generic\")\n",
    "best_segment = best_segment.drop('email_version_personalized', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday_Monday</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "      <th>hour_binned_morning</th>\n",
       "      <th>hour_binned_afternoon</th>\n",
       "      <th>prediction</th>\n",
       "      <th>user_country</th>\n",
       "      <th>purchase_binned</th>\n",
       "      <th>email_text</th>\n",
       "      <th>email_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.755067</td>\n",
       "      <td>ES</td>\n",
       "      <td>High</td>\n",
       "      <td>short_email</td>\n",
       "      <td>personalized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750606</td>\n",
       "      <td>UK</td>\n",
       "      <td>High</td>\n",
       "      <td>long_email</td>\n",
       "      <td>generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.725791</td>\n",
       "      <td>US</td>\n",
       "      <td>High</td>\n",
       "      <td>long_email</td>\n",
       "      <td>personalized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7361</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.715544</td>\n",
       "      <td>FR</td>\n",
       "      <td>High</td>\n",
       "      <td>short_email</td>\n",
       "      <td>personalized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.675495</td>\n",
       "      <td>UK</td>\n",
       "      <td>Low</td>\n",
       "      <td>short_email</td>\n",
       "      <td>generic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      weekday_Monday  weekday_Saturday  weekday_Sunday  weekday_Thursday  weekday_Tuesday  weekday_Wednesday  hour_binned_morning  hour_binned_afternoon  prediction user_country purchase_binned   email_text email_version\n",
       "55                 0                 0               0                 0                1                  0                    1                      0    0.755067           ES            High  short_email  personalized\n",
       "943                0                 0               0                 0                0                  1                    0                      1    0.750606           UK            High   long_email       generic\n",
       "3                  0                 0               0                 1                0                  0                    1                      0    0.725791           US            High   long_email  personalized\n",
       "7361               1                 0               0                 0                0                  0                    1                      0    0.715544           FR            High  short_email  personalized\n",
       "3390               0                 1               0                 0                0                  0                    0                      1    0.675495           UK             Low  short_email       generic"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_segment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weekday\n",
    "best_segment['weekday'] = np.where(best_segment['weekday_Monday'] == 1, \"Monday\", \n",
    "                                    np.where(best_segment['weekday_Saturday'] == 1, \"Saturday\", \n",
    "                                       np.where(best_segment['weekday_Sunday'] == 1, \"Sunday\",\n",
    "                                          np.where(best_segment['weekday_Thursday'] == 1, \"Thursday\", \n",
    "                                              np.where(best_segment['weekday_Tuesday'] == 1, \"Tuesday\",\n",
    "                                                   np.where(best_segment['weekday_Wednesday'] == 1, \"Wednesday\",\n",
    "                                                      \"Friday\"\n",
    "))))))\n",
    "best_segment = best_segment.drop([e for e in list(data_unique) if e.startswith('weekday_')], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hour\n",
    "best_segment['hour_binned'] = np.where(best_segment['hour_binned_afternoon'] == 1, \"afternoon\", \n",
    "                                   np.where(best_segment['hour_binned_morning'] == 1, \"morning\", \n",
    "                                     \"night\"\n",
    "))\n",
    "best_segment = best_segment.drop([e for e in list(data_unique) if e.startswith('hour_binned_')], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>user_country</th>\n",
       "      <th>purchase_binned</th>\n",
       "      <th>email_text</th>\n",
       "      <th>email_version</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.755067</td>\n",
       "      <td>ES</td>\n",
       "      <td>High</td>\n",
       "      <td>short_email</td>\n",
       "      <td>personalized</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>0.750606</td>\n",
       "      <td>UK</td>\n",
       "      <td>High</td>\n",
       "      <td>long_email</td>\n",
       "      <td>generic</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.725791</td>\n",
       "      <td>US</td>\n",
       "      <td>High</td>\n",
       "      <td>long_email</td>\n",
       "      <td>personalized</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7361</th>\n",
       "      <td>0.715544</td>\n",
       "      <td>FR</td>\n",
       "      <td>High</td>\n",
       "      <td>short_email</td>\n",
       "      <td>personalized</td>\n",
       "      <td>Monday</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>0.675495</td>\n",
       "      <td>UK</td>\n",
       "      <td>Low</td>\n",
       "      <td>short_email</td>\n",
       "      <td>generic</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>afternoon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction user_country purchase_binned   email_text email_version    weekday hour_binned\n",
       "55      0.755067           ES            High  short_email  personalized    Tuesday     morning\n",
       "943     0.750606           UK            High   long_email       generic  Wednesday   afternoon\n",
       "3       0.725791           US            High   long_email  personalized   Thursday     morning\n",
       "7361    0.715544           FR            High  short_email  personalized     Monday     morning\n",
       "3390    0.675495           UK             Low  short_email       generic   Saturday   afternoon"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_segment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a model that returns the best email strategy for each user and that’s how we should be sending email to maximize overall click-through-rate. Btw note how even the best email strategy has super low model predictions for users with no purchases, regardless of the country. Once again, you won’t win those people just by tweaking the email.\n",
    "\n",
    "Estimate A/B test gains\n",
    "\n",
    "Now that we have come up with a personalized strategy to send emails, the last step is to test it. In order to test, we would run our personalized algorithm on a randomized fraction of users and compare its results with the current email strategy.\n",
    "\n",
    "In order to run the test though, we still have to convince our product manager that it makes sense to run the test from a cost-opportunity standpoint. And the best way to do that is giving them an estimate of by how much we think we could potentially increase click-rate. That way they can figure out whether it makes sense.\n",
    "\n",
    "This is pretty straightforward. Since we know the predicted probability for each group, we can just estimate the weighted average to guess the final overall click-rate. However, there is one caveat:\n",
    "\n",
    "We cannot simply take the predicted probability from the model. After all, our model is not perfect and had a pretty high class 1 error. There are segments where our model is predicting more than 75%! That’s never going to happen in practice, we will never get 75% clicks. What we need to do is to adjust the predicted probabilities after taking into account the model expected error. That is:\n",
    "\n",
    "Assume, for instance, that your model output is 0.8, so it is predicting 80% clicks. You know, based on the confusion matrix when you built the model, that when your model predicts class 1 is right 5% of the times and when it predicts class 0 is wrong 2% of the times. So if my model is predicting 80% class 1 (and therefore 20% class 0), am actually expecting:\n",
    "\n",
    "0.80.05 + 0.20.02 = ~4% clicks, which is not the original 80%, but it would still be a huge improvement if my starting point is 2%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First let's get count by group. We need this for the weighted average at the end\n",
    "count_segment = data[['user_country','purchase_binned']].groupby(['user_country','purchase_binned']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_country</th>\n",
       "      <th>purchase_binned</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES</td>\n",
       "      <td>None</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES</td>\n",
       "      <td>Low</td>\n",
       "      <td>3785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES</td>\n",
       "      <td>High</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR</td>\n",
       "      <td>None</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_country purchase_binned  counts\n",
       "0           ES            None    1368\n",
       "1           ES             Low    3785\n",
       "2           ES          Medium    3389\n",
       "3           ES            High    1422\n",
       "4           FR            None    1341"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_segment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the proportion instead of the counts. Just easier to deal with to later get weighted average\n",
    "count_segment['weight'] = count_segment['counts'].div(count_segment['counts'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_country</th>\n",
       "      <th>purchase_binned</th>\n",
       "      <th>counts</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES</td>\n",
       "      <td>None</td>\n",
       "      <td>1368</td>\n",
       "      <td>0.013687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES</td>\n",
       "      <td>Low</td>\n",
       "      <td>3785</td>\n",
       "      <td>0.037869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3389</td>\n",
       "      <td>0.033907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES</td>\n",
       "      <td>High</td>\n",
       "      <td>1422</td>\n",
       "      <td>0.014227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR</td>\n",
       "      <td>None</td>\n",
       "      <td>1341</td>\n",
       "      <td>0.013417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_country purchase_binned  counts    weight\n",
       "0           ES            None    1368  0.013687\n",
       "1           ES             Low    3785  0.037869\n",
       "2           ES          Medium    3389  0.033907\n",
       "3           ES            High    1422  0.014227\n",
       "4           FR            None    1341  0.013417"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_segment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge it, so in our final dataset we also have weight\n",
    "best_segment = pd.merge(best_segment, count_segment).sort_values('prediction',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's add class1 and class 0 errors to the dataset. We will take it from the test error confusion matrix\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(test['clicked'], rf.predict(test.drop('clicked', axis=1)), labels=[0, 1]))\n",
    "  \n",
    "#We define positive predictive value (ppv) as the proportion of times the model is right when it predicts 1, this is also called precision \n",
    "ppv = conf_matrix.loc[1,1]/(conf_matrix.loc[1,1]+conf_matrix.loc[0,1])\n",
    "  \n",
    "#We also need false positive rate (FPR). Indeed, those are actual clicks (the model is mistakenly predicting non-click, but it is actually a click)\n",
    "fpr = conf_matrix.loc[1,0]/(conf_matrix.loc[1,0]+conf_matrix.loc[0,0])\n",
    "  \n",
    "#Adjusted predicted click-rate for each segment\n",
    "best_segment['adjusted_prediction'] = best_segment['prediction'] * ppv + (1-best_segment['prediction']) * fpr\n",
    "  \n",
    "#Finally, let's multiply this by the weight of each segment in the dataset and compare it with the starting click-rate\n",
    "CTR_comparison = pd.DataFrame( {'predicted_click_rate':[(best_segment['adjusted_prediction']*best_segment['weight']).sum()],\n",
    "                                    'old_click_rate':[data['clicked'].mean()]\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Positive Rate(TPR)\n",
    "\n",
    "Recall\n",
    "\n",
    "Sensitivity = sum(True Positive)/sum(condition positive) \n",
    "\n",
    "Positive predictive value(PPV)\n",
    "\n",
    "precision = sum(true positive)/sum(predicted condition positive) \n",
    "\n",
    "condition positive(P), the number of real positive cases in the data \n",
    "\n",
    "condition negative N: the number of real negative cases in the data \n",
    "\n",
    "fpr, false psotive rate = sum(false positive)/sum(condition negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30751</td>\n",
       "      <td>2529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>557</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  30751  2529\n",
       "1    557   146"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_click_rate</th>\n",
       "      <th>old_click_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037558</td>\n",
       "      <td>0.0207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted_click_rate  old_click_rate\n",
       "0              0.037558          0.0207"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTR_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, personalization is expected to beat the old strategy by almost 2X. This is huge. We won’t really know for sure what happens until we run a proper A/B test, but this is more than enough to justify running the test. When you use models to predict what would happen in the real world, always adjust predictions based on the model class errors\n",
    "If we are used to DS tutorials and/or have never worked on actual data, we might think that the model performance was very bad. Our model precision was ~5%. As matter of fact, that was actually really good. Our starting click-through-rate is 2%. A 5% precision means we have found a region of space with 2.5X probability of clicking. That’s huge when we deal with real data. And, at the end, our overall predicted click-through-rate went from 2% to 3.7%. That’s also huge. It would mean almost doubling up whatever revenue is coming from emails.\n",
    "\n",
    "Anything higher than that is highly unrealistic and usually happens only when you apply models to some made-up data whose only goal is to make the model predict well.\n",
    "\n",
    "we can notice that certain segments have very low weight. So that might be a noisy area. This does not impact much our final estimate because we multiplied each group adjusted prediction by their weight. However, often you want to do personalization only if you have at least a certain number of people in your training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
